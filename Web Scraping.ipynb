{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3eb6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e68c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'bs4' module separately\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc80dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de BeautifulSoup: 4.12.2\n",
      "Versión de requests: 2.31.0\n"
     ]
    }
   ],
   "source": [
    "# Print the versions of BeautifulSoup and requests libraries\n",
    "print(\"Versión de BeautifulSoup:\",bs4.__version__)\n",
    "print(\"Versión de requests:\", requests.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1daaebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de BeautifulSoup: 4.12.2\n",
      "Versión de requests: 2.31.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4feea69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL, make a request to it, and store the HTML content\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish/'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3397097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afec0b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the type of 'soup' object\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e1e10cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>¿Por qué comprar con nosotros?</h2>\n"
     ]
    }
   ],
   "source": [
    "# Find the first 'h2' tag in the HTML and print it\n",
    "primer_h2 = soup.find('h2')\n",
    "print(primer_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ec1d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2>¿Por qué comprar con nosotros?</h2>, <h2>\r\n",
      "                  #Novedades\r\n",
      "                </h2>, <h2>\r\n",
      "            Nuestros <span>productos</span>\n",
      "</h2>, <h2>\r\n",
      "            Testimonios de clientes\r\n",
      "          </h2>, <h2 class=\"heading-container\">\r\n",
      "          Tabla de precios\r\n",
      "        </h2>]\n"
     ]
    }
   ],
   "source": [
    "# Find all 'h2' tags in the HTML and print them as a list\n",
    "h2_todos = soup.find_all('h2')\n",
    "print(h2_todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82788c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2>¿Por qué comprar con nosotros?</h2>]\n"
     ]
    }
   ],
   "source": [
    "# Find the first 'h2' tag with a limit of 1 and print it\n",
    "h2_uno_solo = soup.find_all('h2',limit=1)\n",
    "print(h2_uno_solo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff495aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "\r\n",
      "                  #Novedades\r\n",
      "                \n",
      "\r\n",
      "            Nuestros productos\n",
      "\n",
      "\r\n",
      "            Testimonios de clientes\r\n",
      "          \n",
      "\r\n",
      "          Tabla de precios\r\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Loop through all 'h2' tags and print their text content\n",
    "for seccion in h2_todos:\n",
    "  print(seccion.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ddc87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "#Novedades\n",
      "Nuestrosproductos\n",
      "Testimonios de clientes\n",
      "Tabla de precios\n"
     ]
    }
   ],
   "source": [
    "# Loop through all 'h2' tags and print their text content without extra whitespace\n",
    "for seccion in h2_todos:\n",
    "  print(seccion.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30017cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"heading-container heading-center\" id=\"acerca\">\n",
      "<h2>¿Por qué comprar con nosotros?</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\" id=\"productos\">\n",
      "<h2>\r\n",
      "            Nuestros <span>productos</span>\n",
      "</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h3>Suscríbete para obtener descuentos y ofertas</h3>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h2>\r\n",
      "            Testimonios de clientes\r\n",
      "          </h2>\n",
      "</div>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Find all 'div' tags with a specific class and print them\n",
    "divs = soup.find_all('div', class_ = \"heading-container heading-center\")\n",
    "\n",
    "for div in divs:\n",
    "  print(div)\n",
    "  print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c3bf7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Parque de patinaje\" src=\"images/slider-bg.jpg\"/>\n",
      "<img alt=\"Patineta 2\" src=\"images/p2.jpg\"/>\n"
     ]
    }
   ],
   "source": [
    "# Find all elements with 'src' attribute and print those ending with '.jpg'\n",
    "src_todos = soup.find_all(src=True)\n",
    "\n",
    "for elemento in src_todos:\n",
    "  if elemento['src'].endswith(\".jpg\"):\n",
    "    print(elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e716c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/arrival-bg-store.png\n",
      "images/p1.png\n",
      "images/p3.png\n",
      "images/p4.png\n",
      "images/p5.png\n",
      "images/p6.png\n",
      "images/p7.png\n",
      "images/p8.png\n",
      "images/p9.png\n",
      "images/p10.png\n",
      "images/p11.png\n",
      "images/p12.png\n",
      "images/client-one.png\n",
      "images/client-two.png\n",
      "images/client-three.png\n",
      "./images/freecodecamp-logo.png\n"
     ]
    }
   ],
   "source": [
    "# Create a list of image URLs and download them\n",
    "url_imagenes = []\n",
    "\n",
    "for i, imagen in enumerate(src_todos):\n",
    "\n",
    "  if imagen['src'].endswith('png'):\n",
    "\n",
    "    print(imagen['src'])\n",
    "    r = requests.get(f\"https://scrapepark.org/courses/spanish/{imagen['src']}\")\n",
    "\n",
    "    with open(f'imagen_{i}.png', 'wb') as f:\n",
    "      f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbb7963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longboard', '$80', '$85', '$90', '$62', '$150']\n"
     ]
    }
   ],
   "source": [
    "# Define a new base URL and retrieve the URL of an iframe\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish'\n",
    "URL_TABLA = soup.find_all('iframe')[0]['src']\n",
    "# Make a request to the iframe URL and parse its HTML content\n",
    "request_tabla = requests.get(f'{URL_BASE}/{URL_TABLA}')\n",
    "\n",
    "html_tabla = request_tabla.text\n",
    "soup_tabla = BeautifulSoup(html_tabla, \"html.parser\")\n",
    "soup_tabla.find('table')\n",
    "# Find all elements with 'th' and 'td' attributes having a specific style and extract their text\n",
    "productos_faltantes = soup_tabla.find_all(['th', 'td'], attrs={'style':'color: red;'})\n",
    "productos_faltantes = [talle.text for talle in productos_faltantes]\n",
    "\n",
    "print(productos_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4174675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producto: Patineta Nueva 1 | precio: 75\n",
      "producto: Patineta Usada 2 | precio: 80\n",
      "producto: Patineta Nueva 3 | precio: 68\n",
      "producto: Patineta Usada 4 | precio: 70\n",
      "producto: Patineta Nueva 5 | precio: 75\n",
      "producto: Patineta Nueva 6 | precio: 58\n",
      "producto: Patineta Nueva 7 | precio: 80\n",
      "producto: Patineta Nueva 8 | precio: 35\n",
      "producto: Patineta Nueva 9 | precio: 165\n",
      "producto: Patineta Usada 10 | precio: 54\n",
      "producto: Patineta Usada 11 | precio: 99\n",
      "producto: Patineta Nueva 12 | precio: 110\n"
     ]
    }
   ],
   "source": [
    "# Find 'div' tags with a specific class and extract product names and prices\n",
    "divs = soup.find_all('div', class_='detail-box')\n",
    "productos = []\n",
    "precios = []\n",
    "\n",
    "for div in divs:\n",
    "  if (div.h6 is not None) and ('Patineta' in div.h5.text):\n",
    "    producto = div.h5.get_text(strip=True)\n",
    "    precio = div.h6.get_text(strip=True).replace('$', '')\n",
    "    # Se puede agregar filtros\n",
    "    print(f'producto: {producto:<16} | precio: {precio}')\n",
    "    productos.append(producto)\n",
    "    precios.append(precio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37799de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scrapepark.org/courses/spanish/contact1\n",
      "Texto que cambia entre páginas en contacto 1 :)\n",
      "https://scrapepark.org/courses/spanish/contact2\n",
      "Texto que cambia entre páginas en contacto 2 :)\n"
     ]
    }
   ],
   "source": [
    "# Define a base URL for contacting pages and loop through two pages to retrieve text content\n",
    "URL_BASE = \"https://scrapepark.org/courses/spanish/contact\"\n",
    "\n",
    "for i in range(1,3):\n",
    "  URL_FINAL = f\"{URL_BASE}{i}\"\n",
    "  print(URL_FINAL)\n",
    "  r = requests.get(URL_FINAL)\n",
    "  soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "  print(soup.h5.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b8523b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 4-444-4444']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expresiones regulares\n",
    "import re\n",
    "\n",
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text\n",
    "\n",
    "# 2. \"Parsear\" ese HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
    "# Find all strings matching a regular expression pattern for phone numbers\n",
    "telefonos = soup.find_all(string=re.compile(\"\\d+-\\d+-\\d+\"))\n",
    "telefonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30401eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENÚ\n",
      "© 2022 \n",
      "El string 'carpincho' no fue encontrado\n",
      "\r\n",
      "                  Patineta Nueva 1\r\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "# List of strings to search for in the HTML\n",
    "strings_a_buscar = [\"MENÚ\", \"©\", \"carpincho\", \"Patineta\"]\n",
    "\n",
    "for string in strings_a_buscar:\n",
    "  try:\n",
    "    resultado = soup.find(string=re.compile(string))\n",
    "    print(resultado.text)\n",
    "  except AttributeError:\n",
    "    print(f\"El string '{string}' no fue encontrado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b742385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert 'productos' and 'precios' headers into their respective lists\n",
    "productos.insert(0, \"productos\")\n",
    "precios.insert(0, \"precios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f9b1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary using 'productos' as keys and 'precios' as values\n",
    "datos = dict(zip(productos, precios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1cc9636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('productos', 'precios'), ('Patineta Nueva 1', '75'), ('Patineta Usada 2', '80'), ('Patineta Nueva 3', '68'), ('Patineta Usada 4', '70'), ('Patineta Nueva 5', '75'), ('Patineta Nueva 6', '58'), ('Patineta Nueva 7', '80'), ('Patineta Nueva 8', '35'), ('Patineta Nueva 9', '165'), ('Patineta Usada 10', '54'), ('Patineta Usada 11', '99'), ('Patineta Nueva 12', '110')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dictionary items\n",
    "datos.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7ade986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'csv' module and write the dictionary to a CSV file\n",
    "import csv\n",
    "\n",
    "with open('datos.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(datos.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0493dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
